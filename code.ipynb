{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "509939d4-c710-450a-ba82-818f942576e3",
   "metadata": {},
   "source": [
    "# Assignment 1 ( Spell Correction )\n",
    "## Lecture Assignment\n",
    "Given a dictionary D and a spelling error corpus C for the English language, calculate the average success at\n",
    "k (s@k) for the minimum edit distance (MED) algorithm for all misspelled tokens in C. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd757875-e646-4832-9cd0-d41c612b7ba6",
   "metadata": {},
   "source": [
    "a) Use WordNet1 as the dictionary D. A Python interface to WordNet is PyDictionary2 which is available\n",
    "opensource3.  \n",
    "b) Use Birkbeck4 spelling error corpus. This corpus includes the most common misspelled tokens and the\n",
    "correct spell in pairs. For instance (‘desing’, ‘design’).  \n",
    "c) Success at k (s@k) measures whether the correct spell of the token happens to be in the top-k (most similar,\n",
    "least distant) list of tokens that are retrieved by the MED from the dictionary D. For instance, given ‘desing’\n",
    "from Birkbeck corpus, the top-5 most similar (least distant) tokens to ‘desing’ based on MED from WordNet\n",
    "are [‘desi’, ‘design’, ‘designer’, ‘designate’, ‘despair’]. Then, s@1 is 0 since the correct spell from Birkbeck\n",
    "is ‘design’ which is not happening at the first item. However, s@k for k≥2 is 1. Report the average s@k for\n",
    "k={1, 5, 10} using PyTrec_Eval_Terrier5.  \n",
    "d) Comparing each misspelled word with all words in a dictionary takes time. You have to come up with\n",
    "workarounds such as parallel runs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8667c6c2-ef83-489f-81b3-0c4b8fbb0d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from heapq import nlargest\n",
    "from concurrent.futures import ThreadPoolExecutor # for parallel distance calculation\n",
    "import concurrent.futures\n",
    "import time\n",
    "import pytrec_eval\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768337c9-fda5-4180-823a-41fb84a6f14e",
   "metadata": {},
   "source": [
    "### LevenshteinDistance\n",
    "I used this link to get more insight about it : https://www.scaler.com/topics/levenshtein-distance-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79d9764-006c-43a1-9558-54c7f463daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshteinDistance(A, B):\n",
    "    if len(A) > len(B):\n",
    "        A, B = B, A  # Ensuring A is the smaller string\n",
    "\n",
    "    N, M = len(A), len(B)\n",
    "    prev_row = list(range(M + 1))\n",
    "\n",
    "    for i in range(1, N + 1):\n",
    "        current_row = [i]\n",
    "        # two one-dimensional arrays (prev_row and current_row), significantly reducing memory usage\n",
    "        for j in range(1, M + 1):\n",
    "            # I would intentionally write the following lines of code like Piecewise Function of Levenshtein for more readability\n",
    "            insertions = prev_row[j] + 1\n",
    "            deletions = current_row[j - 1] + 1\n",
    "            substitutions = prev_row[j - 1] + (A[i - 1] != B[j - 1])\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        prev_row = current_row\n",
    "\n",
    "    return prev_row[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177f6c25-62b6-4d03-8217-7ced98830f02",
   "metadata": {},
   "source": [
    "## Necessary functions\n",
    "\n",
    "We need some functions to make our work easier for retrieving words from our dictionary.\n",
    "As you can see for the filter words function, we assumed that similar words should not be different in terms of length so we put some restrictions on it. This will help us to reduce the amount of time we need for running our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcb352f-8fea-4ba0-a61d-53bc9bf5f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Since going through all the words in a dictionary is not sufficient, we are going to put restrictions on it\n",
    "def filter_words(token, max_length_diff=3):\n",
    "    special_characters = set('!@#$%^&()-+=.:?/;][{}|\\~`1234567890')\n",
    "    length = len(token)\n",
    "    # Restriction\n",
    "    min_length, max_length = length - max_length_diff, length + max_length_diff\n",
    "    return [w for w in wn.words(lang='eng') # getting the word from wordnet\n",
    "            if min_length <= len(w) <= max_length \n",
    "            and not special_characters.intersection(w)]\n",
    "\n",
    "\n",
    "def find_closest_match(token, top_n=10):\n",
    "    words_chklst = filter_words(token)\n",
    "    distances = []\n",
    "\n",
    "    with ThreadPoolExecutor() as executor: # speed up the process ( OPTIMIZATION )\n",
    "        futures = {executor.submit(levenshteinDistance, token, w): w for w in words_chklst}\n",
    "        for future in futures:\n",
    "            w = futures[future]\n",
    "            try:\n",
    "                distance = future.result()\n",
    "                distances.append((distance, w))\n",
    "            except Exception as exc:\n",
    "                print(f\"{w} generated an exception: {exc}\")\n",
    "\n",
    "    return nlargest(top_n, distances, key=lambda x: -x[0])\n",
    "\n",
    "def return_top_1_5_10_words(da):\n",
    "    token, correct_spelling = da\n",
    "    token_distance = find_closest_match(token, 10)\n",
    "    result = {\n",
    "        'incorrect': token,\n",
    "        'correct': correct_spelling,\n",
    "        1: token_distance[:1],\n",
    "        5: token_distance[:5],\n",
    "        10: token_distance\n",
    "    }\n",
    "    return result\n",
    "\n",
    "def return_success_at_k(result_list):\n",
    "    success_dict = {1: [], 5: [], 10: []}\n",
    "    for d in result_list:\n",
    "        crr = d['correct']\n",
    "        for k in [1, 5, 10]:\n",
    "            success_dict[k].append(int(crr in [w[1] for w in d[k]]))\n",
    "\n",
    "    return success_dict\n",
    "\n",
    "\n",
    "def update_results_eval(results_eval, result, k, divisor):\n",
    "    for word in result[k]:\n",
    "        results_eval[word] = results_eval.get(word, 0) + 1 / divisor\n",
    "\n",
    "# Example Usage\n",
    "data = [(\"design\", \"design\"), (\"algoritm\", \"algorithm\")]\n",
    "results = [return_top_1_5_10_words(da) for da in data]\n",
    "success = return_success_at_k(results)\n",
    "print(success)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4873877-1ee0-497f-a7e4-116c6f7785e4",
   "metadata": {},
   "source": [
    "## Birkbeck\n",
    "Since Birkbeck has so many files and working with them could be confusing, I instead used the preprocessed version of it and you can find it in this **<a href=\"https://www.dcs.bbk.ac.uk/~roger/corpora.html\">link</a>**.  \n",
    "You can find some information about the data in here:  \n",
    "* The birkbeck file contains 36,133 misspellings of 6,136 words. It is an amalgamation of errors taken from the native-speaker section (British or American writers) of the Birkbeck spelling error corpus, a collection of files of spelling errors gathered from various sources, available as separate files with detailed documentation from the Oxford Text Archive. It includes the results of spelling tests and errors from free writing, taken mostly from schoolchildren, university students or adult literacy students. Most of them were originally handwritten.\n",
    "\n",
    "* Each **correct** word is preceded by a `dollar` sign and followed by its misspellings, each on one line, without duplicates. (A misspelling might appear more than once in the corpus, but only as a misspelling of different words.) Where the spelling or misspelling contained a space, this has been replaced by an underscore (a_lot, Christ_mas). While most of the misspellings are non-words, there are also some real-word errors, such as \"omitted\" for \"admitted\".\n",
    "\n",
    "* Correct spellings of dictionary words are given in Oxford English form. Where the misspellings were taken from American writers, attempts at specifically American forms (color, theater etc.) have been excluded. Where a correct American form appears as a misspelling, it represents a British writer's attempt at the British form, such as \"color\" for \"colour\". Apart from dictionary words, the correct spellings also contain some proper nouns, abbreviations, words with apostrophes or hyphens, made-up words and two-word items (e.g. \"too much\") where the misspelling was a single string (\"tomuch\").\n",
    "\n",
    "* Users of this corpus should bear in mind that it includes the efforts of young children and extremely poor spellers being subjected to spelling tests way beyond their ability, so some of the misspellings are very different from their targets; the single letter \"o\", for example, appears as a misspelling of the word \"accordingly\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f822680-97ab-4954-b657-5e58a6783b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the correct and incorrect words from Wordnet dictionary \n",
    "corr = []\n",
    "incorr = []\n",
    "total_word_count = 0  # Initialize word count\n",
    "\n",
    "with open('data/missp.txt', 'r') as data:\n",
    "    for line in data:\n",
    "        line = line.strip().lower()  # Processing the line\n",
    "        words = line.split()  # Splitting the line into words\n",
    "        total_word_count += len(words)  # Adding the number of words in the line to the total count\n",
    "\n",
    "        if line.startswith('$'):\n",
    "            current_correct = line[1:]  # Processing for correct words\n",
    "        else:\n",
    "            corr.append(current_correct)\n",
    "            incorr.append(line)\n",
    "\n",
    "# total_word_count now holds the total number of words in the file\n",
    "print(\"Total number of words:\", total_word_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9527728d-b26e-4333-aa45-d7641cf86aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr[5: 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a33de-8d02-48dc-a8c0-005f1a60bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorr[5: 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a53267-8c5a-4674-960c-22fd0b57f33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since testing on all words is not sufficient we just explore some random words \n",
    "correct = corr[5: 10]\n",
    "incorrect = incorr[5: 10]\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    results = list(executor.map(return_top_1_5_10_words, zip(incorrect, correct)))\n",
    "\n",
    "# Diagnostic print statements\n",
    "print(\"Number of results:\", len(results))\n",
    "print(\"First few results:\", results[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc831bd-f88f-4e4b-948c-942d3c869d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming 'results' is prepared correctly\n",
    "success_at_k = return_success_at_k(results)\n",
    "\n",
    "# Prepare the query and results_eval dictionaries\n",
    "query = {result[\"incorrect\"]: {result[\"correct\"]: 1} for result in results}\n",
    "results_eval = {}\n",
    "\n",
    "for result in results:\n",
    "    incorrect_word = result[\"incorrect\"]\n",
    "    results_eval[incorrect_word] = {}\n",
    "\n",
    "    # Update results for top 1, 5, and 10 words\n",
    "    for k in [1, 5, 10]:\n",
    "        divisor = k if k > 1 else 1  # Avoid division by zero\n",
    "        for word in result[k]:\n",
    "            if word not in results_eval[incorrect_word]:\n",
    "                results_eval[incorrect_word][word] = 1 / divisor\n",
    "\n",
    "# Evaluation using pytrec_eval\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(query, {'success'})\n",
    "evaluated_results = evaluator.evaluate(results_eval)\n",
    "\n",
    "# Printing a subset of the evaluated results\n",
    "subset_keys = list(evaluated_results.keys())[:5]  # Adjust as needed\n",
    "subset_evaluated_results = {k: evaluated_results[k] for k in subset_keys}\n",
    "print(json.dumps(subset_evaluated_results, indent=1))\n",
    "\n",
    "# Aggregate measures for all queries\n",
    "aggregated_measures = {}\n",
    "for measure in next(iter(evaluated_results.values())).keys():\n",
    "    aggregated_measures[measure] = pytrec_eval.compute_aggregated_measure(\n",
    "        measure,\n",
    "        [query_measures[measure] for query_measures in evaluated_results.values()]\n",
    "    )\n",
    "\n",
    "# Print aggregated measures\n",
    "for measure, avg in aggregated_measures.items():\n",
    "    print(f\"Average Success {measure}: {avg}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
